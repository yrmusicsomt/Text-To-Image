{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Download the base model and sample some images from it"
      ],
      "metadata": {
        "id": "uDOdVmXBlVFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all the Huggingface python packages"
      ],
      "metadata": {
        "id": "RVViRa9wjSz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install accelerate\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "ka9En2Osxcjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set an environment variable for the base model to be fine-tuned"
      ],
      "metadata": {
        "id": "MeIOf3Ntjcwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MODEL_NAME=stabilityai/stable-diffusion-2-1\n",
        "# %env MODEL_NAME=OFA-Sys/small-stable-diffusion-v0 #could fit to colab 15G but quality is not so good"
      ],
      "metadata": {
        "id": "wdBF3ocL9Xg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a simple function to plot a list of images returned from the model when generating"
      ],
      "metadata": {
        "id": "RJEAMdNejtL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    from matplotlib import pyplot as plt\n",
        "    plt.figure()\n",
        "    f, axarr = plt.subplots(1, len(images), figsize=(20,10))\n",
        "    for ax, img in zip(axarr.flatten(), images):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uL0VsPKLNX2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the relevant python libraries to load and sample from the Stable Diffusion model"
      ],
      "metadata": {
        "id": "FpvlGW2Qj_Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import DiffusionPipeline"
      ],
      "metadata": {
        "id": "-gcAw4q-x6Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step we initialise the model and move it to the GPU (you need to choose the correct runtime on google colab to run this command). This step will also trigger the download of the model. The model is a few GB, it might take some time but it will be faster than what you expect. üòè"
      ],
      "metadata": {
        "id": "1KasH3uZkNHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(os.getenv('MODEL_NAME'), torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "5oQeEnoN0-tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the text prompt for generating the images and run the actual generation."
      ],
      "metadata": {
        "id": "OQB9vMUPkrD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"isometric view of a skyscraper in the style of a city building game\"\n",
        "images = pipe(prompt, num_images_per_prompt=6).images"
      ],
      "metadata": {
        "id": "tVTkHqmhDtfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the images from the base model with our function:"
      ],
      "metadata": {
        "id": "4zbM0bePkyhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(images)"
      ],
      "metadata": {
        "id": "HrRnjdPvNtI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT:** We need to free up the memory of the GPU to be able to start the actual training, let's delete the python variables and collect all the garbage using the garbage collector. Finally we use torch to empty the GPU memory"
      ],
      "metadata": {
        "id": "FFoGxsBZlATD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flush the GPU memory to be able to run the training\n",
        "del pipe\n",
        "del images"
      ],
      "metadata": {
        "id": "Bu5ZH2hL5QZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "fCPO1sLv8DnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Fine-tune the model"
      ],
      "metadata": {
        "id": "7ORm8pDDlkFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's clone the dataset and the hugging face code which contains the finetuning script"
      ],
      "metadata": {
        "id": "WEr_MLkBlphE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/Loulblemo/diffusion_skyscrapers_city_building\n",
        "!git clone https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "ZsIID-kM5pFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set some flags for the finetuning script, the dataset to be used and the number of iterations. Since the dataset we chose is small and we want to finetune quickly using the colab free tier, let's only finetune for 50 epochs"
      ],
      "metadata": {
        "id": "FicdZX2KlxnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%env dataset_name=diffusion_skyscrapers_city_building\n",
        "# No need to train the model for long to see meaningful results.\n",
        "%env max_training_epochs = 50"
      ],
      "metadata": {
        "id": "grbWbL_s8QF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n"
      ],
      "metadata": {
        "id": "-Q2yY67OeorQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we run the actual fine-tuning script. **IMPORTANT:** Remember if you want to train on google's free T4 GPU it's crucial to add the flag\n",
        "\n",
        "```\n",
        "--use_8bit_adam\n",
        "```\n",
        "We will save the model in the *city-building-model* folder\n"
      ],
      "metadata": {
        "id": "NlDRQYshmH_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --dataset_name=$dataset_name \\\n",
        "  --use_ema \\\n",
        "  --use_8bit_adam \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=$max_training_epochs \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"city-building-model\"\n"
      ],
      "metadata": {
        "id": "iP99BN6M8Zrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Sample from the finetuned model"
      ],
      "metadata": {
        "id": "ij5MUon8mg97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the new model in the GPU (this time we don't need to Download anything as the fine-tuned model has been saved locally) and generate some more images"
      ],
      "metadata": {
        "id": "tNXp8qcQmuUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained('city-building-model', torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "prompt = \"isometric view of a skyscraper in the style of a city building game\"\n",
        "images = pipe(prompt, num_images_per_prompt=6).images"
      ],
      "metadata": {
        "id": "9HDLPlJIH6vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new images! Hopefully the quality improved thanks to the finetuning process. You can play with the number of epochs to see how the fine-tuning process impacts the final output üí™"
      ],
      "metadata": {
        "id": "0xqQiXFPm8eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(images)"
      ],
      "metadata": {
        "id": "oeiXolxQIvM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}